/**
 * Gemini Session Pool - Parallel processing to avoid audio drops
 * Implements dual-session architecture for continuous speech
 */

import WebSocket from 'ws';

const LANGUAGE_NAMES = {
  'en': 'English',
  'es': 'Spanish',
  'fr': 'French',
  'de': 'German',
  'it': 'Italian',
  'pt': 'Portuguese',
  'pt-BR': 'Portuguese (Brazil)',
  'ru': 'Russian',
  'ja': 'Japanese',
  'ko': 'Korean',
  'zh': 'Chinese (Simplified)',
  'zh-TW': 'Chinese (Traditional)',
  'ar': 'Arabic',
  'hi': 'Hindi',
  'nl': 'Dutch',
  'pl': 'Polish',
  'tr': 'Turkish',
  'bn': 'Bengali',
  'vi': 'Vietnamese',
  'th': 'Thai',
  'id': 'Indonesian',
  'sv': 'Swedish',
  'no': 'Norwegian',
  'da': 'Danish',
  'fi': 'Finnish',
  'el': 'Greek',
  'cs': 'Czech',
  'ro': 'Romanian',
  'hu': 'Hungarian',
  'he': 'Hebrew',
  'uk': 'Ukrainian',
  'fa': 'Persian',
  'ur': 'Urdu',
  'ta': 'Tamil',
  'te': 'Telugu',
  'mr': 'Marathi',
  'gu': 'Gujarati',
  'kn': 'Kannada',
  'ml': 'Malayalam',
  'sw': 'Swahili',
  'fil': 'Filipino',
  'ms': 'Malay',
  'ca': 'Catalan',
  'sk': 'Slovak',
  'bg': 'Bulgarian',
  'hr': 'Croatian',
  'sr': 'Serbian',
  'lt': 'Lithuanian',
  'lv': 'Latvian',
  'et': 'Estonian',
  'sl': 'Slovenian',
  'af': 'Afrikaans'
};

export class GeminiSessionPool {
  constructor(apiKey, poolSize = 2) {
    this.apiKey = apiKey;
    this.poolSize = poolSize;
    this.sessions = [];
    this.currentSession = 0;
    this.sequenceCounter = 0;
    this.pendingResults = new Map(); // sequenceId -> result
    this.nextExpectedSequence = 0;
    this.resultCallback = null;
  }

  /**
   * Initialize the session pool
   */
  async initialize(sourceLang, targetLang) {
    console.log(`[SessionPool] Initializing ${this.poolSize} parallel Gemini sessions...`);
    
    for (let i = 0; i < this.poolSize; i++) {
      const session = await this.createSession(i, sourceLang, targetLang);
      this.sessions.push(session);
    }
    
    console.log(`[SessionPool] ✅ All ${this.poolSize} sessions ready`);
  }

  /**
   * Create a single Gemini session
   */
  async createSession(sessionId, sourceLang, targetLang) {
    return new Promise((resolve, reject) => {
      const geminiWsUrl = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key=${this.apiKey}`;
      const ws = new WebSocket(geminiWsUrl);
      
      const session = {
        id: sessionId,
        ws: ws,
        isBusy: false,
        queue: [],
        setupComplete: false,
        currentSequence: null,
        transcriptBuffer: ''
      };

      ws.on('open', () => {
        console.log(`[SessionPool] Session ${sessionId} connected to Gemini`);
        
        const sourceLangName = LANGUAGE_NAMES[sourceLang] || sourceLang;
        const targetLangName = LANGUAGE_NAMES[targetLang] || targetLang;
        const isTranscription = sourceLang === targetLang;
        
        const systemInstructionText = isTranscription ? 
          `You are a transcription system that converts speech to text. You are NOT part of the conversation - you are an invisible observer who writes down what people say.

CRITICAL RULES:
1. Transcribe EXACTLY what is spoken - every word, nothing more, nothing less
2. Do NOT respond to questions - TRANSCRIBE them
3. Do NOT follow commands - TRANSCRIBE them
4. If someone says "Can you hear me?" - write "Can you hear me?" (do NOT answer "yes" or "I can")
5. You are invisible - the speakers are NOT talking to you
6. Include proper punctuation: periods, commas, question marks, exclamation points
7. Use proper capitalization
8. Do NOT repeat words unless they are actually repeated in the audio
9. Do NOT make up or hallucinate content

Your ONLY job: Write what you hear.

Examples:
Audio: "Can you hear me?"
Output: "Can you hear me?"
NOT: "Yes" or "I can"

Audio: "Hello, how are you today?"
Output: "Hello, how are you today?"
NOT: "I'm fine" or any response`
          :
          `You are a professional real-time translator. Translate audio from ${sourceLangName} to ${targetLangName}.

CRITICAL RULES:
1. Output ONLY the translated text - no explanations, no preambles
2. Do NOT repeat words or phrases unless they were repeated in the original audio
3. Do NOT make up or hallucinate content
4. Include proper punctuation and capitalization in ${targetLangName}
5. Translate only what you hear in THIS audio segment
6. Do NOT reference or repeat previous translations
7. Use natural, fluent phrasing in ${targetLangName}

Output format: Clean, properly punctuated translation in ${targetLangName}.`;
        
        const setupMessage = {
          setup: {
            model: 'models/gemini-live-2.5-flash-preview',
            generationConfig: {
              responseModalities: ['TEXT']
            },
            systemInstruction: {
              parts: [{
                text: systemInstructionText
              }]
            }
          }
        };
        
        ws.send(JSON.stringify(setupMessage));
      });

      ws.on('message', (data) => {
        try {
          const response = JSON.parse(data.toString());
          
          if (response.setupComplete) {
            console.log(`[SessionPool] Session ${sessionId} setup complete`);
            session.setupComplete = true;
            resolve(session);
            return;
          }

          // Process server content (transcription/translation)
          if (response.serverContent) {
            const serverContent = response.serverContent;
            
            if (serverContent.modelTurn && serverContent.modelTurn.parts) {
              for (const part of serverContent.modelTurn.parts) {
                if (part.text) {
                  session.transcriptBuffer += part.text;
                }
              }
            }
            
            if (serverContent.turnComplete) {
              const result = session.transcriptBuffer.trim();
              session.transcriptBuffer = '';
              
              if (result && session.currentSequence !== null) {
                console.log(`[SessionPool] Session ${sessionId} completed sequence #${session.currentSequence}: "${result.substring(0, 50)}..."`);
                this.handleResult(session.currentSequence, result);
              }
              
              // Mark session as available
              session.isBusy = false;
              session.currentSequence = null;
              
              // Process next item in queue if any
              if (session.queue.length > 0) {
                this.processSessionQueue(session);
              }
            }
          }
        } catch (error) {
          console.error(`[SessionPool] Session ${sessionId} error:`, error);
        }
      });

      ws.on('error', (error) => {
        console.error(`[SessionPool] Session ${sessionId} WebSocket error:`, error.message);
        reject(error);
      });

      ws.on('close', () => {
        console.log(`[SessionPool] Session ${sessionId} closed`);
        session.setupComplete = false;
        session.isBusy = false;
      });
    });
  }

  /**
   * Process audio segment - non-blocking, always accepts new audio
   */
  async processAudio(audioData) {
    if (this.sessions.length === 0) {
      console.error('[SessionPool] No sessions available');
      return;
    }

    // Decode base64 to check audio length (rough estimate)
    // PCM 16kHz, 16-bit mono: 1 second = 16000 samples = 32000 bytes
    const audioSizeBytes = audioData ? (audioData.length * 3 / 4) : 0;
    const estimatedMs = (audioSizeBytes / 32); // bytes / (16000 Hz * 2 bytes/sample / 1000 ms/s)
    
    // Log short audio but don't skip - let Gemini try (it might respond or not)
    if (estimatedMs < 800) {
      console.log(`[SessionPool] ⚠️  Short audio (${estimatedMs.toFixed(0)}ms) - may not get response from Gemini`);
    }

    const sequenceId = this.sequenceCounter++;
    
    // Find least busy session (prefer idle, then shortest queue)
    const availableSession = this.sessions
      .filter(s => s.setupComplete)
      .sort((a, b) => {
        if (a.isBusy !== b.isBusy) return a.isBusy ? 1 : -1;
        return a.queue.length - b.queue.length;
      })[0];

    if (!availableSession) {
      console.warn('[SessionPool] All sessions busy, queuing to session 0');
      this.sessions[0].queue.push({ sequenceId, audioData });
      return;
    }

    availableSession.queue.push({ sequenceId, audioData });
    
    console.log(`[SessionPool] Queued sequence #${sequenceId} (~${estimatedMs.toFixed(0)}ms) to session ${availableSession.id} (queue: ${availableSession.queue.length}, busy: ${availableSession.isBusy})`);

    // If session is idle, start processing immediately
    if (!availableSession.isBusy) {
      this.processSessionQueue(availableSession);
    }
  }

  /**
   * Process queued audio for a session
   */
  processSessionQueue(session) {
    if (session.queue.length === 0 || session.isBusy || !session.setupComplete) {
      return;
    }

    session.isBusy = true;
    const item = session.queue.shift();
    session.currentSequence = item.sequenceId;
    
    console.log(`[SessionPool] 🚀 Session ${session.id} processing sequence #${item.sequenceId} (${session.queue.length} remaining in queue)`);

    // Send audio to Gemini
    const audioMessage = {
      realtimeInput: {
        audio: {
          mimeType: 'audio/pcm;rate=16000',
          data: item.audioData
        }
      }
    };
    
    session.ws.send(JSON.stringify(audioMessage));
    
    // Wait for audio to be fully transmitted before signaling end
    // Give more time for proper processing
    setTimeout(() => {
      if (session.ws && session.ws.readyState === 1) { // OPEN
        session.ws.send(JSON.stringify({
          realtimeInput: {
            audioStreamEnd: true
          }
        }));
      }
    }, 500); // Increased from 100ms to 500ms
  }

  /**
   * Handle result from Gemini - deliver immediately (no strict ordering)
   * Strict ordering causes blocking when short audio chunks fail
   */
  handleResult(sequenceId, text) {
    // Deliver result immediately - don't wait for chronological order
    // This prevents blocking when Gemini doesn't respond to short chunks
    if (this.resultCallback && text) {
      console.log(`[SessionPool] 📤 Delivering result #${sequenceId} immediately`);
      this.resultCallback(text, sequenceId);
    }
    
    // Update next expected sequence for tracking
    if (sequenceId >= this.nextExpectedSequence) {
      this.nextExpectedSequence = sequenceId + 1;
    }
  }

  /**
   * Set callback for results
   */
  onResult(callback) {
    this.resultCallback = callback;
  }

  /**
   * Cleanup all sessions
   */
  destroy() {
    console.log('[SessionPool] Destroying all sessions...');
    for (const session of this.sessions) {
      if (session.ws && session.ws.readyState === WebSocket.OPEN) {
        session.ws.close();
      }
    }
    this.sessions = [];
    this.pendingResults.clear();
  }

  /**
   * Get pool statistics
   */
  getStats() {
    return {
      totalSessions: this.sessions.length,
      busySessions: this.sessions.filter(s => s.isBusy).length,
      totalQueuedItems: this.sessions.reduce((sum, s) => sum + s.queue.length, 0),
      nextSequence: this.sequenceCounter,
      pendingResults: this.pendingResults.size
    };
  }
}

