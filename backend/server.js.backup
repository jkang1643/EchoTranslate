/**
 * EchoTranslate - Backend Server
 * Copyright (c) 2025 EchoTranslate. All Rights Reserved.
 * 
 * PROPRIETARY AND CONFIDENTIAL
 * 
 * MIGRATION NOTES:
 * - Replaced Gemini Live API with OpenAI Realtime API
 * - Uses OpenAI Realtime for continuous speech transcription
 * - Maintains all existing features and session management
 * - Updated environment variable from GEMINI_API_KEY to OPENAI_API_KEY
 * 
 * This software contains proprietary and confidential information.
 * Unauthorized copying, modification, distribution, or use of this
 * software is strictly prohibited.
 * 
 * See LICENSE file for complete terms and conditions.
 */

import express from "express";
import WebSocket, { WebSocketServer } from "ws";
import fetch from "node-fetch";
import cors from "cors";
import path from "path";
import { fileURLToPath } from "url";
import dotenv from "dotenv";
import sessionStore from "./sessionStore.js";
import translationManager from "./translationManager.js";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Load .env from backend directory
dotenv.config({ path: path.join(__dirname, '.env') });

const app = express();
const port = process.env.PORT || 3001;

// Middleware
app.use(cors());
app.use(express.json());

// Store active sessions for tracking
const activeSessions = new Map();

// Language code to full name mapping
const LANGUAGE_NAMES = {
  'en': 'English',
  'es': 'Spanish',
  'fr': 'French',
  'de': 'German',
  'it': 'Italian',
  'pt': 'Portuguese',
  'pt-BR': 'Portuguese (Brazil)',
  'ru': 'Russian',
  'ja': 'Japanese',
  'ko': 'Korean',
  'zh': 'Chinese (Simplified)',
  'zh-TW': 'Chinese (Traditional)',
  'ar': 'Arabic',
  'hi': 'Hindi',
  'nl': 'Dutch',
  'pl': 'Polish',
  'tr': 'Turkish',
  'bn': 'Bengali',
  'vi': 'Vietnamese',
  'th': 'Thai',
  'id': 'Indonesian',
  'sv': 'Swedish',
  'no': 'Norwegian',
  'da': 'Danish',
  'fi': 'Finnish',
  'el': 'Greek',
  'cs': 'Czech',
  'ro': 'Romanian',
  'hu': 'Hungarian',
  'he': 'Hebrew',
  'uk': 'Ukrainian',
  'fa': 'Persian',
  'ur': 'Urdu',
  'ta': 'Tamil',
  'te': 'Telugu',
  'mr': 'Marathi',
  'gu': 'Gujarati',
  'kn': 'Kannada',
  'ml': 'Malayalam',
  'sw': 'Swahili',
  'fil': 'Filipino',
  'ms': 'Malay',
  'ca': 'Catalan',
  'sk': 'Slovak',
  'bg': 'Bulgarian',
  'hr': 'Croatian',
  'sr': 'Serbian',
  'lt': 'Lithuanian',
  'lv': 'Latvian',
  'et': 'Estonian',
  'sl': 'Slovenian',
  'af': 'Afrikaans'
};

// Create WebSocket server for clients
const wss = new WebSocketServer({ noServer: true });

// Create HTTP server
const server = app.listen(port, '0.0.0.0', () => {
  console.log(`[Backend] Server running on port ${port}`);
  console.log(`[Backend] Local: http://localhost:${port}`);
  console.log(`[Backend] WebSocket: ws://localhost:${port}/translate`);
  console.log(`[Backend] For network access, use your local IP address instead of localhost`);
});

// Import WebSocket handlers
import { handleHostConnection, handleListenerConnection } from './websocketHandler.js';
import { handleSoloMode } from './soloModeHandler.js';

// Handle WebSocket upgrades
server.on("upgrade", (req, socket, head) => {
  if (req.url?.startsWith("/translate")) {
    wss.handleUpgrade(req, socket, head, (ws) => {
      wss.emit("connection", ws, req);
    });
  } else {
    socket.destroy();
  }
});

// Handle WebSocket connections
wss.on("connection", async (clientWs, req) => {
  console.log("[Backend] New WebSocket client connected");

  // Parse URL parameters
  const url = new URL(req.url, `http://localhost:${port}`);
  const role = url.searchParams.get('role'); // 'host' or 'listener'
  const sessionId = url.searchParams.get('sessionId');
  const targetLang = url.searchParams.get('targetLang');
  const userName = decodeURIComponent(url.searchParams.get('userName') || 'Anonymous');

  // Route to appropriate handler
  if (role === 'host' && sessionId) {
    handleHostConnection(clientWs, sessionId);
    return;
  } else if (role === 'listener' && sessionId) {
    handleListenerConnection(clientWs, sessionId, targetLang || 'en', userName);
    return;
  }

  // Fall back to solo mode for backward compatibility
  // UNIFIED: Now uses OpenAIRealtimePool just like host mode
  console.log("[Backend] Solo mode connection - using OpenAIRealtimePool");
  handleSoloMode(clientWs);
  // OLD INLINE SOLO MODE CODE REMOVED
  // Now using handleSoloMode() which uses OpenAIRealtimePool (same as host mode)
});

// ========================================
// SESSION MANAGEMENT ENDPOINTS
// ========================================

/**
          modalities: ['text'],
          instructions: 'Output only the translation/transcription. No conversation. No greetings. No extra words.'
        }
      }));
      
      isStreamingAudio = false;
    }
  };

  // MIGRATION NOTE: Replaced attachGeminiHandlers with attachOpenAIHandlers
  // OpenAI Realtime uses event-based protocol instead of Gemini's message format
  const attachOpenAIHandlers = (ws) => {
    ws.on("error", (error) => {
      console.error("[Backend] OpenAI Realtime WebSocket error:", error.message || error);
      if (clientWs.readyState === WebSocket.OPEN) {
        clientWs.send(JSON.stringify({
          type: 'error',
          message: 'OpenAI Realtime connection error: ' + (error.message || 'Unknown error')
        }));
      }
    });

    ws.on("message", (data) => {
      try {
        const event = JSON.parse(data.toString());
        // Log event type but not full content to avoid spam
        if (!event.type?.startsWith('response.audio')) {
          console.log("[Backend] OpenAI event:", event.type);
        }

        // MIGRATION NOTE: OpenAI Realtime uses event types instead of response types
        switch (event.type) {
          case 'session.created':
          case 'session.updated':
            console.log("[Backend] OpenAI Realtime session ready");
            setupComplete = true;
            
            // Process any queued messages
            if (messageQueue.length > 0) {
              console.log(`[Backend] Processing ${messageQueue.length} queued messages after setup...`);
              const queuedMessages = [...messageQueue];
              messageQueue = [];
              
              queuedMessages.forEach(queued => {
                if (queued.type === 'audio') {
                  // Re-send audio through the message handler
                  clientWs.emit('message', JSON.stringify(queued.message));
                }
              });
            }
            break;

          case 'error':
            console.error('[Backend] OpenAI Realtime error:', event.error);
            if (clientWs.readyState === WebSocket.OPEN) {
              clientWs.send(JSON.stringify({
                type: 'error',
                message: event.error?.message || 'OpenAI Realtime error'
              }));
            }
            break;

          case 'response.created':
            currentResponseId = event.response?.id;
            console.log('[Backend] Response started:', currentResponseId);
            break;

          case 'response.audio_transcript.delta':
            // Accumulate transcript deltas
            if (event.delta) {
              transcriptBuffer += event.delta;
            }
            break;

          case 'response.text.delta':
            // Accumulate text deltas
            if (event.delta) {
              transcriptBuffer += event.delta;
            }
            break;

          case 'response.audio_transcript.done':
          case 'response.text.done':
            // Transcript complete - send to client
            if (transcriptBuffer.trim() && clientWs.readyState === WebSocket.OPEN) {
              console.log('[Backend] Transcript complete:', transcriptBuffer.substring(0, 100));
              clientWs.send(JSON.stringify({
                type: 'translation',
                originalText: '[Audio input]',
                translatedText: transcriptBuffer.trim(),
                timestamp: Date.now()
              }));
            }
            break;

          case 'response.done':
            console.log('[Backend] Response complete - ready for next input');
            
            // Reset state for next turn
            transcriptBuffer = '';
            isStreamingAudio = false;
            currentResponseId = null;
            
            // Notify client ready for next input
            if (clientWs.readyState === WebSocket.OPEN) {
              clientWs.send(JSON.stringify({
                type: 'turn_complete',
                timestamp: Date.now()
              }));
            }
            break;
        }
      } catch (error) {
        console.error("[Backend] Error processing OpenAI event:", error);
        // Send error message to client instead of raw data
        if (clientWs.readyState === WebSocket.OPEN) {
          clientWs.send(JSON.stringify({
            type: 'error',
            message: 'Error processing translation response'
          }));
        }
      }
    });

    ws.on("close", async (code, reason) => {
      console.log(`[Backend] OpenAI Realtime connection closed. Code: ${code}, Reason: ${reason || 'No reason provided'}`);
      console.log(`[Backend] Session ID: ${legacySessionId}, Reconnect attempts: ${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS}`);
      
      // Reset streaming state on disconnect
      isStreamingAudio = false;
      setupComplete = false;
      transcriptBuffer = '';
      currentResponseId = null;
      
      // Check for authentication errors (OpenAI uses 1008 for policy violations)
      if (code === 1008 || code === 1011) {
        reconnectAttempts++;
        
        if (reconnectAttempts >= MAX_RECONNECT_ATTEMPTS) {
          console.error('[Backend] ❌ PERSISTENT API ERROR - Stopping reconnection attempts');
          console.error('[Backend] Please verify:');
          console.error('[Backend] 1. OPENAI_API_KEY is valid');
          console.error('[Backend] 2. API key has access to Realtime API');
          console.error('[Backend] 3. Account has sufficient credits');
          
          if (clientWs.readyState === WebSocket.OPEN) {
            clientWs.send(JSON.stringify({
              type: 'error',
              message: '❌ Persistent API Error: Unable to connect after multiple attempts. Please check your OpenAI API key and account status.',
              code: code,
              persistent: true
            }));
          }
          return; // Stop trying
        }
        
        console.warn(`[Backend] ⚠️  Code ${code} received (attempt ${reconnectAttempts}/${MAX_RECONNECT_ATTEMPTS}) - will retry...`);
      }
      
      // Attempt to reconnect
      if (clientWs.readyState === WebSocket.OPEN && !reconnecting) {
        reconnecting = true;
        
        // Exponential backoff: 500ms, 1s, 2s, 4s
        const backoffDelay = Math.min(500 * Math.pow(2, reconnectAttempts), 4000);
        console.log(`[Backend] Attempting to reconnect in ${backoffDelay}ms...`);
        
        try {
          // Wait with exponential backoff
          await new Promise(resolve => setTimeout(resolve, backoffDelay));
          
          // Reconnect to OpenAI Realtime
          openaiWs = await connectToOpenAI();
          
          // Re-attach all the event handlers
          attachOpenAIHandlers(openaiWs);
          
          reconnecting = false;
          
          // Reset counter on successful connection
          if (code !== 1008 && code !== 1011) {
            reconnectAttempts = 0;
          }
          
          console.log('[Backend] Successfully reconnected to OpenAI Realtime - waiting for session ready...');
          
          // Messages will be processed when setupComplete is received
          // Don't process queue here to avoid sending before setup is complete
          
        } catch (error) {
          reconnecting = false;
          console.error('[Backend] Failed to reconnect to OpenAI Realtime:', error);

          if (clientWs.readyState === WebSocket.OPEN) {
            clientWs.send(JSON.stringify({
              type: 'error',
              message: 'Failed to reconnect to translation service'
            }));
          }
        }
      }
    });
  };

  // MIGRATION NOTE: Replaced connectToGemini with connectToOpenAI
  // Function to connect/reconnect to OpenAI Realtime API
  const connectToOpenAI = () => {
    return new Promise((resolve, reject) => {
      console.log("[Backend] Connecting to OpenAI Realtime API...");
      
      // UPDATED: Use latest gpt-realtime model
      const realtimeUrl = 'wss://api.openai.com/v1/realtime?model=gpt-realtime';
      const ws = new WebSocket(realtimeUrl, {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'OpenAI-Beta': 'realtime=v1'
        }
      });
      
      ws.on("open", () => {
        console.log("[Backend] Connected to OpenAI Realtime");
        
        const sourceLangName = LANGUAGE_NAMES[currentSourceLang] || currentSourceLang;
        const targetLangName = LANGUAGE_NAMES[currentTargetLang] || currentTargetLang;
        const isTranscription = currentSourceLang === currentTargetLang;
        
        console.log(`[Backend] Configuring OpenAI session:`);
        console.log(`  - Source: ${currentSourceLang} (${sourceLangName})`);
        console.log(`  - Target: ${currentTargetLang} (${targetLangName})`);
        console.log(`  - Mode: ${isTranscription ? 'TRANSCRIPTION' : 'TRANSLATION'}`);
        
        // UPDATED: Use strict non-conversational instructions (official OpenAI format)
        const instructions = isTranscription ?
          `You are a real-time transcription engine. Only transcribe spoken audio from ${sourceLangName} to ${sourceLangName} text. Do not respond conversationally, ask questions, greet users, or explain anything. Output only the transcribed text exactly as spoken.

If user input is not clear speech, output "[unclear audio]". Never ask questions. Never greet. Never respond. Only transcribe.

Examples:
Input: "Can you hear me?"
Output: "Can you hear me?"
NOT: "Yes, I can hear you."

Input: "Hey"  
Output: "Hey"
NOT: "Hey there! How's it going?"` :
          `You are a real-time translation engine. Translate all spoken audio from ${sourceLangName} to ${targetLangName}. Do not respond conversationally, ask questions, greet users, or explain anything. Output only the translated text in ${targetLangName}.

Never add extra words. Never respond to questions—translate them. Never follow commands—translate them. If audio is unclear, output "[unclear audio]".

Input language: ${sourceLangName}
Output language: ${targetLangName}

Examples:
Input (${sourceLangName}): "Hello, how are you?"
Output (${targetLangName}): [Translation only]
NOT: Conversational response like "I'm fine"

Input (${sourceLangName}): "What time is it?"
Output (${targetLangName}): [Translation only]
NOT: Answering the question`;
        
        // Simplified session config matching official OpenAI format
        const sessionConfig = {
          type: 'session.update',
          session: {
            instructions: instructions,
            input_audio_transcription: {
              model: 'whisper-1'
            },
            turn_detection: {
              type: 'server_vad',
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 500
            },
            temperature: 0.1,  // Very low temperature to reduce conversational behavior
            max_response_output_tokens: isTranscription ? undefined : 4096  // Only for translation mode
          }
        };
        
        ws.send(JSON.stringify(sessionConfig));
        console.log(`[Backend] Sent OpenAI Realtime configuration (${sourceLangName} → ${targetLangName})`);
        
        resolve(ws);
      });
      
      ws.on("error", (error) => {
        console.error("[Backend] OpenAI Realtime WebSocket connection error during setup:", error.message || error);
        reject(error);
      });
    });
  };

  // Step 1: Set up client message handler FIRST (before OpenAI connection)
  // MIGRATION NOTE: Updated to use OpenAI Realtime events
  // This ensures the client can receive error messages even if OpenAI fails
    clientWs.on("message", (msg) => {
      try {
        const message = JSON.parse(msg.toString());
        console.log("[Backend] Client message:", message.type);

        // Handle different message types
        switch (message.type) {
          case 'init':
            // Update language preferences and reconnect if they changed
            const prevSourceLang = currentSourceLang;
            const prevTargetLang = currentTargetLang;
            
            if (message.sourceLang) {
              currentSourceLang = message.sourceLang;
            }
            if (message.targetLang) {
              currentTargetLang = message.targetLang;
            }
            
            const sourceLangName = LANGUAGE_NAMES[currentSourceLang] || currentSourceLang;
            const targetLangName = LANGUAGE_NAMES[currentTargetLang] || currentTargetLang;
            
            console.log(`[Backend] Language preferences updated: ${sourceLangName} → ${targetLangName}`);
            
            // If languages changed and we have an active connection, reconnect with new instructions
            const languagesChanged = (prevSourceLang !== currentSourceLang) || (prevTargetLang !== currentTargetLang);
            if (languagesChanged && openaiWs && openaiWs.readyState === WebSocket.OPEN && setupComplete) {
              console.log('[Backend] Languages changed, reconnecting with new instructions...');
              openaiWs.close();
              // The close handler will trigger reconnection with new languages
            }
            
            // Client is initializing - session already set up
            if (clientWs.readyState === WebSocket.OPEN) {
              clientWs.send(JSON.stringify({
                type: 'session_ready',
                sessionId: legacySessionId,
                message: `Translation session ready: ${sourceLangName} → ${targetLangName}`
              }));
            }
            break;

          case 'text':
            // Text messages not supported in legacy mode with OpenAI Realtime
            // Could use Chat API for text if needed, but skip for now
            console.log('[Backend] Text message received but not implemented in OpenAI Realtime legacy mode');
            break;

          case 'audio':
            // MIGRATION NOTE: Send audio to OpenAI using input_audio_buffer.append
            if (openaiWs && openaiWs.readyState === WebSocket.OPEN && setupComplete) {
              if (!isStreamingAudio) {
                console.log(`[Backend] Starting new audio stream`);
                isStreamingAudio = true;
              }
              
              // Send audio chunk using OpenAI Realtime input_audio_buffer.append
              const audioAppendEvent = {
                type: 'input_audio_buffer.append',
                audio: message.audioData
              };
              
              console.log(`[Backend] Appending audio to OpenAI Realtime buffer`);
              openaiWs.send(JSON.stringify(audioAppendEvent));
              
            } else if (!setupComplete) {
              // Queue audio if setup not complete yet
              if (messageQueue.length < 10) {
                console.log('[Backend] Setup not complete, queuing audio message...');
                messageQueue.push({ type: 'audio', message });
              }
            } else {
              // Queue audio during reconnection (but limit queue size to avoid memory issues)
              if (messageQueue.length < 10) {
                console.log('[Backend] OpenAI reconnecting, queuing audio message...');
                messageQueue.push({ type: 'audio', message });
              } else {
                console.log('[Backend] Message queue full, dropping audio chunk');
              }
            }
            break;
          
          case 'audio_end':
            // Client explicitly signals end of audio input
            console.log('[Backend] Client signaled audio end, committing buffer');
            commitAudioBuffer();
            break;

          default:
            console.log(`[Backend] Unknown message type: ${message.type}`);
        }
      } catch (error) {
        console.error("[Backend] Error processing client message:", error);
      }
    });

  // Step 2: Handle client disconnects
    clientWs.on("close", () => {
      console.log("[Backend] Client disconnected");
      
      // Close OpenAI Realtime connection
      if (openaiWs && openaiWs.readyState === WebSocket.OPEN) {
        openaiWs.close();
      }
      
      // Remove session
      if (legacySessionId) {
        activeSessions.delete(legacySessionId);
      }
      
      // Reset state
      isStreamingAudio = false;
      setupComplete = false;
      transcriptBuffer = '';
      currentResponseId = null;
      messageQueue = [];
    });

  // Step 3: Now connect to OpenAI Realtime (after client handlers are ready)
  // MIGRATION NOTE: Replaced Gemini connection with OpenAI Realtime
  (async () => {
    try {
      legacySessionId = `session_${Date.now()}`;
      console.log(`[Backend] Starting legacy session with OpenAI Realtime: ${legacySessionId}`);
      
      // Check if API key is configured
      if (!process.env.OPENAI_API_KEY) {
        throw new Error('OPENAI_API_KEY is not configured in environment variables');
      }
      
      openaiWs = await connectToOpenAI();
      console.log(`[Backend] OpenAI Realtime connection established for session: ${legacySessionId}`);

      // Attach OpenAI event handlers
      attachOpenAIHandlers(openaiWs);

      // Store session for tracking
      activeSessions.set(legacySessionId, {
        clientWs,
        openaiWs,
        startTime: Date.now()
      });

      // Send session ready message to client
      if (clientWs.readyState === WebSocket.OPEN) {
        clientWs.send(JSON.stringify({
          type: 'session_ready',
          sessionId: legacySessionId,
          message: 'Translation session ready with OpenAI Realtime'
        }));
      }

    } catch (err) {
      console.error("[Backend] Session initialization error:", err);
      console.error("[Backend] Error stack:", err.stack);
      
      if (clientWs.readyState === WebSocket.OPEN) {
        clientWs.send(JSON.stringify({
          type: 'error',
          message: `Failed to initialize translation session: ${err.message}`
        }));
      }
    }
  })();
});

// ========================================
// SESSION MANAGEMENT ENDPOINTS
// ========================================

/**
 * POST /session/start
 * Creates a new live translation session for a host
 */
app.post('/session/start', (req, res) => {
  try {
    const { sessionId, sessionCode } = sessionStore.createSession();
    
    res.json({
      success: true,
      sessionId,
      sessionCode,
      wsUrl: `/translate?role=host&sessionId=${sessionId}`
    });
  } catch (error) {
    console.error('[Backend] Error creating session:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

/**
 * POST /session/join
 * Allows a listener to join an existing session
 */
app.post('/session/join', (req, res) => {
  try {
    const { sessionCode, targetLang, userName } = req.body;
    
    if (!sessionCode) {
      return res.status(400).json({
        success: false,
        error: 'Session code is required'
      });
    }
    
    const session = sessionStore.getSessionByCode(sessionCode);
    
    if (!session) {
      return res.status(404).json({
        success: false,
        error: 'Session not found. Please check the code and try again.'
      });
    }
    
    if (!session.isActive) {
      return res.status(400).json({
        success: false,
        error: 'Session is not active yet. The host needs to start broadcasting.'
      });
    }
    
    res.json({
      success: true,
      sessionId: session.sessionId,
      sessionCode: session.sessionCode,
      sourceLang: session.sourceLang,
      targetLang: targetLang || 'en',
      wsUrl: `/translate?role=listener&sessionId=${session.sessionId}&targetLang=${targetLang || 'en'}&userName=${encodeURIComponent(userName || 'Anonymous')}`
    });
  } catch (error) {
    console.error('[Backend] Error joining session:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

/**
 * GET /session/:sessionCode/info
 * Get session information
 */
app.get('/session/:sessionCode/info', (req, res) => {
  try {
    const { sessionCode } = req.params;
    const session = sessionStore.getSessionByCode(sessionCode);
    
    if (!session) {
      return res.status(404).json({
        success: false,
        error: 'Session not found'
      });
    }
    
    const stats = sessionStore.getSessionStats(session.sessionId);
    
    res.json({
      success: true,
      session: stats
    });
  } catch (error) {
    console.error('[Backend] Error getting session info:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

/**
 * GET /sessions
 * Get all active sessions (for admin/debugging)
 */
app.get('/sessions', (req, res) => {
  try {
    const sessions = sessionStore.getAllSessions();
    res.json({
      success: true,
      sessions
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    activeSessions: activeSessions.size,
    liveTranslationSessions: sessionStore.getAllSessions().length,
    model: 'gpt-realtime',
    apiProvider: 'OpenAI',
    endpoint: '/translate'
  });
});

// Test translation endpoint (using OpenAI Chat API)
// MIGRATION NOTE: Replaced Gemini API with OpenAI Chat Completions API
app.post('/test-translation', async (req, res) => {
  try {
    const { text, sourceLang, targetLang } = req.body;
    
    const sourceLangName = LANGUAGE_NAMES[sourceLang] || sourceLang || 'auto-detect';
    const targetLangName = LANGUAGE_NAMES[targetLang] || targetLang || 'English';

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: `You are a professional translator. Translate from ${sourceLangName} to ${targetLangName}. Output only the translation, no explanations.`
          },
          {
            role: 'user',
            content: text
          }
        ],
        temperature: 0.3
      })
    });

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: { message: 'Unknown error' } }));
      throw new Error(`Translation request failed: ${error.error?.message || response.statusText}`);
    }

    const result = await response.json();
    const translatedText = result.choices?.[0]?.message?.content?.trim() || '';

    res.json({
      originalText: text,
      translatedText: translatedText,
      sourceLang: sourceLangName,
      targetLang: targetLangName
    });
  } catch (error) {
    console.error('Test translation error:', error);
    res.status(500).json({ error: error.message });
  }
});

// Serve static files in production
if (process.env.NODE_ENV === 'production') {
  app.use(express.static(path.join(__dirname, '../frontend/dist')));

  app.get('*', (req, res) => {
    res.sendFile(path.join(__dirname, '../frontend/dist/index.html'));
  });
}

// MIGRATION NOTE: Updated startup messages for OpenAI Realtime
console.log("[Backend] Starting OpenAI Realtime Translation Server...");
console.log("[Backend] WebSocket endpoint: ws://localhost:" + port + "/translate");
console.log("[Backend] API Provider: OpenAI Realtime API");
console.log("[Backend] Model: gpt-realtime (latest)");
console.log("[Backend] API Key configured:", process.env.OPENAI_API_KEY ? 'Yes ✓' : 'No ✗ (ERROR!)');
if (!process.env.OPENAI_API_KEY) {
  console.error("[Backend] ERROR: OPENAI_API_KEY not found in environment variables!");
  console.error("[Backend] Please create a .env file with: OPENAI_API_KEY=your_api_key_here");
}